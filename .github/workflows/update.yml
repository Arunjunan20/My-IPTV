name: Auto-Update index.html

on:
  schedule:
    - cron: '0 */2 * * *' # Runs every 2 hours
  workflow_dispatch: # Allows manual run

permissions:
  contents: write

jobs:
  update-playlist:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install requests
        run: pip install requests

      - name: Run Update Script
        env:
          FILE_NAME: 'index.html'
        run: |
          cat <<EOF > update_script.py
          import requests
          import json
          import os
          import re
          import sys
          import time
          from datetime import datetime

          # --- CONFIGURATION ---
          file_name = os.getenv("FILE_NAME", "index.html")
          
          # Source URLs
          # Priority 0: Hotstar (Jio/Star)
          # Priority 1: Zee (Tiger629/Joker)
          source_urls = [
              "https://livetv.cb7.pages.dev/hotstar",
              "https://raw.githubusercontent.com/tiger629/m3u/refs/heads/main/joker.m3u"
          ]

          # Categories
          categories = {
              "Tamil": [
                  "Sun TV HD", "Star Vijay HD", "Colors Tamil HD", "Zee Tamil HD", "KTV HD",
                  "Sun Music HD","Kalaignar TV", "Jaya TV HD", "Raj TV", "Adithya TV",
                  "Sun life"
              ],
              "Movies": [
                  "Zee Thirai HD", "Vijay Super HD", "Vijay Takkar", "J Movies", "Raj Digital Plus",
                  "Star Movies HD", "Star Movies Select HD", 
              ],
              "Music": [
                   "Raj Musix", "Jaya Max"
              ],
              "Entertainment": [
                  "Zee Tamil HD APAC","Colors Infinity HD", "Zee Café HD", "&Flix HD",
                  "&Prive HD", "MTV HD", "Disney International HD", "Nick HD+"
              ],
              "News": [
                  "Sun News", "News7 Tamil", "Thanthi TV"
              ],
              "Sports": [
                  "Star Sports HD1", "Star Sports HD2", "Star Sports 3", 
                  "Star Sports 1 Tamil HD", "Star Sports 2 Tamil HD"
              ],
              "Kids": [
                  "Nick Hindi", "Sonic Hindi", "Pogo Hindi", "Cartoon Network Hindi",
                  "Cartoon Network HD+ Hindi", "Chutti TV", "Disney Channel", "Disney Junior",
                  "Hungama", "Super Hungama", "Nick Jr", "Sony Yay Hindi" 
              ],
              "Infotainment": [
                  "History TV18 HD", "Discovery HD Hindi", "National Geographic HD", "Nat Geo Wild HD",
                  "Animal Planet HD Hindi", "Sony BBC Earth HD","Zee Zest HD"
              ]
          }

          # --- HELPER FUNCTIONS ---
          def normalize_name(name):
              if not name: return ""
              return str(name).lower().replace(" ", "").replace("_", "").replace("-", "").strip()

          # --- PARSER ---
          def parse_m3u(content):
              items = []
              lines = content.splitlines()
              current_item = {}
              for line in lines:
                  line = line.strip()
                  if line.startswith("#EXTINF"):
                      current_item = {} 
                      parts = line.rsplit(',', 1)
                      if len(parts) == 2:
                          current_item['name'] = parts[1].strip()
                      id_match = re.search(r'tvg-id="([^"]+)"', line)
                      if id_match: current_item['tvg_id'] = id_match.group(1)
                      logo_match = re.search(r'tvg-logo="([^"]+)"', line)
                      if logo_match: current_item['tvg_logo'] = logo_match.group(1)

                  elif line.startswith("#EXTVLCOPT"):
                      if "http-user-agent=" in line:
                          ua = line.split("http-user-agent=", 1)[1].strip()
                          current_item['user_agent'] = ua
                  
                  elif line.startswith("#KODIPROP"):
                      if "license_key=" in line:
                          key = line.split("license_key=", 1)[1].strip()
                          current_item['drmLicense'] = key
                      elif "license_type=" in line:
                          type_val = line.split("license_type=", 1)[1].strip()
                          current_item['drmScheme'] = type_val
                  
                  elif line.startswith("#EXTHTTP"):
                      if "cookie" in line:
                          try:
                              cookie_match = re.search(r'"cookie"\s*:\s*"([^"]+)"', line)
                              if cookie_match: current_item['cookie'] = cookie_match.group(1)
                          except: pass
                      if "User-Agent" in line:
                          try:
                              ua_match = re.search(r'"User-Agent"\s*:\s*"([^"]+)"', line)
                              if ua_match: current_item['user_agent'] = ua_match.group(1)
                          except: pass

                  elif line and not line.startswith("#"):
                      if 'name' in current_item:
                          current_item['url'] = line
                          items.append(current_item)
                          current_item = {} 
              return items

          # --- MAIN LOGIC ---
          def main():
              all_items = []
              jio_token = None
              timestamp = int(time.time())
              
              print("Phase 1: Harvesting Channels & Scanning for Tokens...")
              
              headers = {
                  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
              }

              for priority_index, base_url in enumerate(source_urls):
                  try:
                      # Add Cache Buster
                      separator = "&" if "?" in base_url else "?"
                      url = f"{base_url}{separator}t={timestamp}"
                      
                      print(f"Downloading Source {priority_index + 1}: {url}...")
                      response = requests.get(url, headers=headers, timeout=30)
                      response.raise_for_status()
                      content = response.text
                      
                      # NUCLEAR SEARCH: Find fresh token in raw text (For Jio)
                      if not jio_token and "__hdnea__=" in content:
                          print(" -> Scanning for fresh Jio Token...")
                          token_match = re.search(r'(__hdnea__=[^"&\s]*)', content)
                          if token_match:
                              jio_token = token_match.group(1)
                              print(f" -> NEW TOKEN FOUND: {jio_token[:25]}...")

                      # Parse M3U or JSON
                      parsed = []
                      if content.strip().startswith("#EXTM3U") or ".m3u" in base_url or "hotstar" in base_url:
                          parsed = parse_m3u(content)
                      else:
                          try:
                              data = json.loads(content)
                              if isinstance(data, dict):
                                  if "channels" in data: parsed = data["channels"]
                                  elif "data" in data: parsed = data["data"]
                                  elif "list" in data: parsed = data["list"]
                                  else: parsed = [data]
                              elif isinstance(data, list): parsed = data
                          except json.JSONDecodeError: 
                              print(" -> Failed to parse as JSON or M3U")
                      
                      if parsed:
                          for item in parsed:
                              item['source_priority'] = priority_index
                          all_items.extend(parsed)
                          print(f" -> Added {len(parsed)} channels.")
                          
                  except Exception as e:
                      print(f"Error fetching source: {e}")

              if not jio_token:
                  print("WARNING: No Jio Token found. Links might be expired.")

              # 3. HARVEST EXISTING DATA (Logos/IDs)
              existing_data = {}
              if os.path.exists(file_name):
                  try:
                      with open(file_name, "r", encoding="utf-8") as f:
                          for line in f:
                              if line.strip().startswith("#EXTINF"):
                                  parts = line.rsplit(',', 1)
                                  if len(parts) == 2:
                                      ch_name = parts[1].strip()
                                      norm_key = normalize_name(ch_name)
                                      existing_data[norm_key] = {}
                                      
                                      logo_match = re.search(r'tvg-logo=["\']([^"\']+)["\']', line)
                                      if logo_match: existing_data[norm_key]['logo'] = logo_match.group(1)
                                      id_match = re.search(r'tvg-id=["\']([^"\']+)["\']', line)
                                      if id_match: existing_data[norm_key]['id'] = id_match.group(1)
                  except Exception: pass

              # 4. Generate Playlist
              print("Phase 3: Generating Playlist...")
              new_playlist_lines = []
              seen_channels = set()
              DEFAULT_UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 ygx/69.1 Safari/537.36"

              for category, targets in categories.items():
                  for target_name in targets:
                      if target_name.lower() in seen_channels:
                          continue
                      
                      matches = [
                          item for item in all_items 
                          if normalize_name(item.get("name") or item.get("title") or item.get("id")) == normalize_name(target_name)
                      ]
                      
                      if matches:
                          matches.sort(key=lambda x: (
                              x.get('source_priority', 99),
                              0 if "BTS" in (x.get("link") or x.get("url") or "") else 1,
                              (x.get("link") or x.get("url") or "").count("_")
                          ))
                          match = matches[0]
                          
                          # 1. RENAME FIRST
                          name = target_name
                          clean_name = re.sub(r'\s*Hindi\s*', '', name, flags=re.IGNORECASE).strip()
                          if clean_name.lower() == "adithya tv":
                              clean_name = "Adithya"

                          # 2. DATA LOOKUP
                          norm_final_name = normalize_name(clean_name)
                          
                          final_id = match.get("tvg_id") or match.get("tvgId") or match.get("id") or ""
                          final_logo = match.get("tvg_logo") or match.get("logo") or ""
                          
                          if norm_final_name in existing_data:
                              if 'id' in existing_data[norm_final_name]: 
                                  final_id = existing_data[norm_final_name]['id']
                              if 'logo' in existing_data[norm_final_name]: 
                                  final_logo = existing_data[norm_final_name]['logo']

                          # --- PROCESSING ---
                          drm_scheme = match.get("drmScheme") or match.get("drm_scheme") or match.get("drm") or ""
                          drm_license = match.get("drmLicense") or match.get("license") or ""
                          
                          raw_link = match.get("link") or match.get("url") or match.get("stream_url") or match.get("hls") or match.get("mpd") or ""
                          link = raw_link.strip()
                          if not link: continue

                          seen_channels.add(target_name.lower())
                          cookie = match.get("cookie") or match.get("cookies") or ""
                          current_ua = match.get("user_agent") or DEFAULT_UA

                          # >>> DETECT PROVIDER (Robust) <<<
                          is_jio = "jio" in link.lower() or "cdn.jio" in link.lower()
                          # Detect Zee if URL contains zee5 OR comes from Source #1 (Tiger629)
                          is_zee = "zee5.com" in link.lower() or match.get('source_priority') == 1

                          # >>> TOKEN & HEADER LOGIC <<<
                          if is_jio:
                              if jio_token:
                                  separator = "&" if "?" in link else "?"
                                  link = f"{link}{separator}{jio_token}"
                                  cookie = jio_token
                              drm_scheme = "clearkey"
                          
                          elif is_zee:
                              cookie = None
                              if drm_license and not drm_scheme:
                                  drm_scheme = "com.widevine.alpha"

                          # Build Output
                          extinf_parts = ["#EXTINF:-1"]
                          if final_id: extinf_parts.append(f'tvg-id="{final_id}"')
                          extinf_parts.append(f'group-title="{category}"')
                          if final_logo: extinf_parts.append(f'tvg-logo="{final_logo}"')
                          
                          header = " ".join(extinf_parts) + "," + clean_name
                          new_playlist_lines.append(header)

                          if drm_license:
                              if not drm_scheme: drm_scheme = "clearkey"
                              new_playlist_lines.append(f"#KODIPROP:inputstream.adaptive.license_type={drm_scheme}")
                              new_playlist_lines.append(f"#KODIPROP:inputstream.adaptive.license_key={drm_license}")
                          
                          new_playlist_lines.append(f"#EXTVLCOPT:http-user-agent={current_ua}")

                          if cookie:
                              clean_cookie = cookie.replace('"', '\\"')
                              new_playlist_lines.append(f'#EXTHTTP:{{"cookie":"{clean_cookie}"}}')
                          elif is_zee:
                              # Force Referer for ALL channels from the Zee source
                              new_playlist_lines.append('#EXTHTTP:{"Referer":"https://www.zee5.com/"}')
                          
                          new_playlist_lines.append(link)
                          new_playlist_lines.append("")

              # 5. Write to File
              if len(new_playlist_lines) < 5:
                  print("CRITICAL ERROR: No channels found. Aborting.")
                  sys.exit(1)

              start_marker = "# >>> JIO_AUTO_START"
              end_marker = "# >>> JIO_AUTO_END"
              
              try:
                  with open(file_name, "r", encoding="utf-8") as f:
                      content = f.read()

                  if start_marker not in content or end_marker not in content:
                      print(f"Error: Markers not found in {file_name}")
                      sys.exit(1)

                  pre_content = content.split(start_marker)[0]
                  post_content = content.split(end_marker)[1]
                  
                  timestamp_line = f"# Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}"
                  
                  new_content = (
                      pre_content + 
                      start_marker + "\n" + 
                      timestamp_line + "\n" + 
                      "\n".join(new_playlist_lines) + "\n" + 
                      end_marker + 
                      post_content
                  )
                  
                  with open(file_name, "w", encoding="utf-8") as f:
                      f.write(new_content)
                      
                  print(f"Success! Updated {file_name} with {len(new_playlist_lines)//6} channels.")

              except FileNotFoundError:
                  print(f"Error: File {file_name} not found.")
                  sys.exit(1)

          if __name__ == "__main__":
              main()
          EOF
          
          python update_script.py

      - name: Commit & Push
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add index.html
          git commit -m "✅ Auto-update playlist in index.html" || echo "No changes to commit"
          git push origin main
